---
title: Blurbs and the Bechdel test
author: Luke McGuinness
date: '2021-04-12'
slug: do-blurbs-predict-whether-films-will-pass-the-bechdel-test
categories:
  - tidymodels
  - prediction
  - machine learning
  - R
  - side-project
tags: []
excerpt: Do promotional blurbs predict whether films will pass the Bechdel test?
math: no
meta: yes
draft: true
---

<script src="index_files/header-attrs/header-attrs.js"></script>


<div id="install-relevant-pacakges" class="section level2">
<h2>Install relevant pacakges</h2>
</div>
<div id="load-the-data" class="section level2">
<h2>Load the data</h2>
<p>For this analysis, I used a TidyTuesday dataset on the Bechdel test. <span class="sidenote-number"></span><span class="sidenote">See <a href = "https://github.com/rfordatascience/tidytuesday/blob/master/data/2021/2021-03-09/readme.md">here</a>.</span>`</p>
<pre class="r"><code>library(tidyverse)</code></pre>
<pre><code>## -- Attaching packages --------------------------------------- tidyverse 1.3.0 --</code></pre>
<pre><code>## v ggplot2 3.3.3     v purrr   0.3.4
## v tibble  3.1.0     v dplyr   1.0.5
## v tidyr   1.1.3     v stringr 1.4.0
## v readr   1.3.1     v forcats 0.5.1</code></pre>
<pre><code>## -- Conflicts ------------------------------------------ tidyverse_conflicts() --
## x dplyr::filter() masks stats::filter()
## x dplyr::lag()    masks stats::lag()</code></pre>
<pre class="r"><code>library(tidytext)

tuesdata &lt;- tidytuesdayR::tt_load(&#39;2021-03-09&#39;)</code></pre>
<pre><code>## --- Compiling #TidyTuesday Information for 2021-03-09 ----</code></pre>
<pre><code>## --- There are 2 files available ---</code></pre>
<pre><code>## --- Starting Download ---</code></pre>
<pre><code>## 
##  Downloading file 1 of 2: `raw_bechdel.csv`
##  Downloading file 2 of 2: `movies.csv`</code></pre>
<pre><code>## --- Download complete ---</code></pre>
<pre class="r"><code>movies &lt;- tuesdata$movies %&gt;%
  mutate(bechdel = binary) %&gt;%
  select(title, plot, bechdel) %&gt;%
  filter(!is.na(plot) &amp; !is.na(bechdel)) %&gt;%
  mutate(text = plot) %&gt;%
  select(-plot)

# Number of words per movie blurb
movies %&gt;%
  unnest_tokens(word, text) %&gt;%
  count(title, name = &quot;total_words&quot;) %&gt;%
  ggplot(aes(total_words)) +
  geom_histogram(fill = &quot;darkorange2&quot;, alpha = 0.8) +
  theme_minimal()</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>I also wanted to have a quick look at the balance between the two outcomes (Pass/Fail) to ensure the dataset was relatively well balanced.</p>
<pre class="r"><code># Number of movies that pass/fail
movies %&gt;%
  ggplot(aes(x = bechdel)) +
  geom_bar(stat = &quot;count&quot;, fill = &quot;darkorange2&quot;, alpha = 0.8) +
  theme_minimal()</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<pre class="r"><code>prop.table(table(movies$bechdel))</code></pre>
<pre><code>## 
##      FAIL      PASS 
## 0.5603015 0.4396985</code></pre>
<p>It seems there are a few more movies that fail the test, but the split is not too far off 50/50.</p>
<div id="build-a-model" class="section level3">
<h3>Build a model</h3>
<p>First things first, split the data into training and testing dataset, using the default split of 3/4 training and 1/4 testing.</p>
<p><label for="tufte-mn-" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-" class="margin-toggle"><span class="marginnote">I like using The Answer to the Ultimate Question of Life, the Universe, and Everything a a seed.</span></p>
<pre class="r"><code>library(tidymodels)</code></pre>
<pre><code>## -- Attaching packages -------------------------------------- tidymodels 0.1.2 --</code></pre>
<pre><code>## v broom     0.7.5      v recipes   0.1.15
## v dials     0.0.9      v rsample   0.0.9 
## v infer     0.5.4      v tune      0.1.3 
## v modeldata 0.1.0      v workflows 0.2.2 
## v parsnip   0.1.5      v yardstick 0.0.7</code></pre>
<pre><code>## -- Conflicts ----------------------------------------- tidymodels_conflicts() --
## x scales::discard() masks purrr::discard()
## x dplyr::filter()   masks stats::filter()
## x recipes::fixed()  masks stringr::fixed()
## x dplyr::lag()      masks stats::lag()
## x yardstick::spec() masks readr::spec()
## x recipes::step()   masks stats::step()</code></pre>
<pre class="r"><code>set.seed(42)
review_split &lt;- initial_split(movies, strata = bechdel)
review_train &lt;- training(review_split)
review_test &lt;- testing(review_split)</code></pre>
<p>Next, I made use of the amazing</p>
<pre class="r"><code>library(textrecipes)
library(stopwords)

review_rec &lt;- recipe(bechdel ~ text, data = review_train) %&gt;%
  step_tokenize(text) %&gt;%
  step_stopwords(text) %&gt;%
  step_tokenfilter(text, max_tokens = 500) %&gt;%
  step_tfidf(text) %&gt;%
  step_normalize(all_predictors())

review_prep &lt;- prep(review_rec)

review_prep</code></pre>
<pre><code>## Data Recipe
## 
## Inputs:
## 
##       role #variables
##    outcome          1
##  predictor          1
## 
## Training data contained 1194 data points and no missing data.
## 
## Operations:
## 
## Tokenization for text [trained]
## Stop word removal for text [trained]
## Text filtering for text [trained]
## Term frequency-inverse document frequency with text [trained]
## Centering and scaling for tfidf_text_accident, ... [trained]</code></pre>
</div>
<div id="section" class="section level3">
<h3></h3>
<pre class="r"><code>lasso_spec &lt;- logistic_reg(penalty = tune(), mixture = 1) %&gt;%
  set_engine(&quot;glmnet&quot;)

lasso_wf &lt;- workflow() %&gt;%
  add_recipe(review_rec) %&gt;%
  add_model(lasso_spec)

lasso_wf</code></pre>
<pre><code>## == Workflow ====================================================================
## Preprocessor: Recipe
## Model: logistic_reg()
## 
## -- Preprocessor ----------------------------------------------------------------
## 5 Recipe Steps
## 
## * step_tokenize()
## * step_stopwords()
## * step_tokenfilter()
## * step_tfidf()
## * step_normalize()
## 
## -- Model -----------------------------------------------------------------------
## Logistic Regression Model Specification (classification)
## 
## Main Arguments:
##   penalty = tune()
##   mixture = 1
## 
## Computational engine: glmnet</code></pre>
<p><label for="tufte-mn-" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-" class="margin-toggle"><span class="marginnote">You may need the development version of <code>recipes</code> for this to work, as per <a href="https://github.com/tidymodels/tune/issues/192">this issue</a></span></p>
<pre class="r"><code>lambda_grid &lt;- grid_regular(penalty(), levels = 40)

set.seed(42)
review_folds &lt;- bootstraps(review_train, strata = bechdel)
review_folds</code></pre>
<pre><code>## # Bootstrap sampling using stratification 
## # A tibble: 25 x 2
##    splits             id         
##    &lt;list&gt;             &lt;chr&gt;      
##  1 &lt;split [1194/440]&gt; Bootstrap01
##  2 &lt;split [1194/445]&gt; Bootstrap02
##  3 &lt;split [1194/437]&gt; Bootstrap03
##  4 &lt;split [1194/447]&gt; Bootstrap04
##  5 &lt;split [1194/443]&gt; Bootstrap05
##  6 &lt;split [1194/446]&gt; Bootstrap06
##  7 &lt;split [1194/434]&gt; Bootstrap07
##  8 &lt;split [1194/435]&gt; Bootstrap08
##  9 &lt;split [1194/454]&gt; Bootstrap09
## 10 &lt;split [1194/436]&gt; Bootstrap10
## # ... with 15 more rows</code></pre>
<pre class="r"><code>doParallel::registerDoParallel()

set.seed(2020)
lasso_grid &lt;- tune_grid(
  lasso_wf,
  resamples = review_folds,
  grid = lambda_grid,
  metrics = metric_set(roc_auc, ppv, npv)
)

lasso_grid %&gt;%
  collect_metrics()</code></pre>
<pre><code>## # A tibble: 120 x 7
##     penalty .metric .estimator  mean     n std_err .config              
##       &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;fct&gt;                
##  1 1.00e-10 npv     binary     0.498    25 0.00580 Preprocessor1_Model01
##  2 1.00e-10 ppv     binary     0.616    25 0.00536 Preprocessor1_Model01
##  3 1.00e-10 roc_auc binary     0.578    25 0.00424 Preprocessor1_Model01
##  4 1.80e-10 npv     binary     0.498    25 0.00580 Preprocessor1_Model02
##  5 1.80e-10 ppv     binary     0.616    25 0.00536 Preprocessor1_Model02
##  6 1.80e-10 roc_auc binary     0.578    25 0.00424 Preprocessor1_Model02
##  7 3.26e-10 npv     binary     0.498    25 0.00580 Preprocessor1_Model03
##  8 3.26e-10 ppv     binary     0.616    25 0.00536 Preprocessor1_Model03
##  9 3.26e-10 roc_auc binary     0.578    25 0.00424 Preprocessor1_Model03
## 10 5.88e-10 npv     binary     0.498    25 0.00580 Preprocessor1_Model04
## # ... with 110 more rows</code></pre>
<pre class="r"><code>best_auc &lt;- lasso_grid %&gt;%
  select_best(&quot;roc_auc&quot;)

best_auc</code></pre>
<pre><code>## # A tibble: 1 x 2
##   penalty .config              
##     &lt;dbl&gt; &lt;fct&gt;                
## 1  0.0289 Preprocessor1_Model34</code></pre>
<pre class="r"><code>final_lasso &lt;- finalize_workflow(lasso_wf, best_auc)

final_lasso</code></pre>
<pre><code>## == Workflow ====================================================================
## Preprocessor: Recipe
## Model: logistic_reg()
## 
## -- Preprocessor ----------------------------------------------------------------
## 5 Recipe Steps
## 
## * step_tokenize()
## * step_stopwords()
## * step_tokenfilter()
## * step_tfidf()
## * step_normalize()
## 
## -- Model -----------------------------------------------------------------------
## Logistic Regression Model Specification (classification)
## 
## Main Arguments:
##   penalty = 0.0289426612471674
##   mixture = 1
## 
## Computational engine: glmnet</code></pre>
<pre class="r"><code>library(vip)</code></pre>
<pre><code>## 
## Attaching package: &#39;vip&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:utils&#39;:
## 
##     vi</code></pre>
<pre class="r"><code>final_lasso %&gt;%
  fit(review_train) %&gt;%
  pull_workflow_fit() %&gt;%
  vi(lambda = best_auc$penalty) %&gt;%
  group_by(Sign) %&gt;%
  arrange(desc(abs(Importance))) %&gt;%
  slice(1:20) %&gt;%
  ungroup() %&gt;%
  mutate(
    Importance = abs(Importance),
    Variable = str_remove(Variable, &quot;tfidf_text_&quot;),
    Variable = fct_reorder(Variable, Importance)
  ) %&gt;%
  ggplot(aes(x = Importance, y = Variable, fill = Sign)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~Sign, scales = &quot;free_y&quot;) +
  labs(y = NULL)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<pre class="r"><code>review_final &lt;- last_fit(final_lasso, review_split)

review_final %&gt;%
  collect_metrics()</code></pre>
<pre><code>## # A tibble: 2 x 4
##   .metric  .estimator .estimate .config             
##   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;fct&gt;               
## 1 accuracy binary         0.606 Preprocessor1_Model1
## 2 roc_auc  binary         0.615 Preprocessor1_Model1</code></pre>
<pre class="r"><code>review_final %&gt;%
  collect_predictions() %&gt;%
  conf_mat(bechdel, .pred_class)</code></pre>
<pre><code>##           Truth
## Prediction FAIL PASS
##       FAIL  209  143
##       PASS   14   32</code></pre>
</div>
</div>
